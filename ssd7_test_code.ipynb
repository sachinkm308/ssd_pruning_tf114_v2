{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "#from models.keras_ssd7 import build_model\n",
    "#from models.keras_ssd7_copy import build_model  #Creating model that can be used for pruning\n",
    "\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
    "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
    "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Pruning imports start\n",
    "\n",
    "import tensorflow_model_optimization as tfmot  #Adding pruning imports\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude   #Adding pruning imports\n",
    "    \n",
    "from tensorflow import keras\n",
    "    \n",
    "### Pruning imports end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                184330    \n",
      "=================================================================\n",
      "Total params: 203,434\n",
      "Trainable params: 203,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "from tensorflow.python import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "#add model layers\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)))\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_step ->  4500\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f475b8bcf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f475b8bcf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f475b8bcf98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f475b8bcf98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d_2 (None, 26, 26, 64)        1218      \n",
      "=================================================================\n",
      "Total params: 1,218\n",
      "Trainable params: 640\n",
      "Non-trainable params: 578\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    import tensorflow_model_optimization as tfmot  #Adding pruning imports\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude   #Adding pruning imports\n",
    "    \n",
    "    input_shape=[10]\n",
    "\n",
    "    epochs = 2\n",
    "    num_images = 18000\n",
    "    end_step = np.ceil(num_images / 8).astype(np.int32) * epochs\n",
    "    print(\"End_step -> \",end_step)\n",
    "\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "    }\n",
    "    \n",
    "    \n",
    "    model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Conv2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)), **pruning_params),\n",
    "  \n",
    "])\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)), **pruning_params)\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(64, kernel_size=3, activation='relu'), **pruning_params)\n",
    "\n",
    "    \n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), **pruning_params))\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.MaxPooling2D(pool_size=(2, 2)), **pruning_params)\n",
    "\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params)])\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(conv1, **pruning_params)])\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_step ->  4500\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecafc0eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecafc0eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecafc0eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecafc0eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecacc79e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecacc79e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecacc79e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecacc79e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f800c562b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f800c562b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f800c562b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f800c562b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca18ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca18ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca18ad30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca18ad30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca9cfdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca9cfdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca9cfdd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca9cfdd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecac3a240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecac3a240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecac3a240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ecac3a240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9efe4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9efe4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9efe4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9efe4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca8ea4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca8ea4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca8ea4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7eca8ea4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9daa2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9daa2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9daa2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9daa2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c1de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c1de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c1de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c1de10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9c84eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9be8da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9be8da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9be8da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9be8da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec97ab828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec97ab828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec97ab828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec97ab828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec98b4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec98b4320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec98b4320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec98b4320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec96fafd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec96fafd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec96fafd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec96fafd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9bc9c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9bc9c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9bc9c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9bc9c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec985ed68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec985ed68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec985ed68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec985ed68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec90e8128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec90e8128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec90e8128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec90e8128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9296b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9296b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9296b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec9296b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e1fa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e1fa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e1fa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e1fa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8f9aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8f9aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8f9aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8f9aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e95630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e95630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8e95630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8ad5a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8ad5a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8ad5a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8ad5a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892f860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892f860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892f860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892fa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec892fa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec89d3128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec89d3128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec89d3128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec89d3128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8d766a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8d766a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8d766a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7f7ec8d766a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 480, 3)]     0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_identity (None, 300, 480, 3)       1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv1 (P (None, 300, 480, 32)      4834      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn1 (Pru (None, 300, 480, 32)      129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu1 (Pr (None, 300, 480, 32)      1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool1 (P (None, 150, 240, 32)      1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2 (P (None, 150, 240, 48)      27698     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn2 (Pru (None, 150, 240, 48)      193       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu2 (Pr (None, 150, 240, 48)      1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool2 (P (None, 75, 120, 48)       1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv3 (P (None, 75, 120, 64)       55362     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn3 (Pru (None, 75, 120, 64)       257       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu3 (Pr (None, 75, 120, 64)       1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool3 (P (None, 37, 60, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv4 (P (None, 37, 60, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn4 (Pru (None, 37, 60, 64)        257       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu4 (Pr (None, 37, 60, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool4 (P (None, 18, 30, 64)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv5 (P (None, 18, 30, 48)        55346     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn5 (Pru (None, 18, 30, 48)        193       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu5 (Pr (None, 18, 30, 48)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool5 (P (None, 9, 15, 48)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv6 (P (None, 9, 15, 48)         41522     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn6 (Pru (None, 9, 15, 48)         193       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu6 (Pr (None, 9, 15, 48)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_pool6 (P (None, 4, 7, 48)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv7 (P (None, 4, 7, 32)          27682     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_bn7 (Pru (None, 4, 7, 32)          129       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_elu7 (Pr (None, 4, 7, 32)          1         \n",
      "=================================================================\n",
      "Total params: 287,603\n",
      "Trainable params: 143,952\n",
      "Non-trainable params: 143,651\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    import tensorflow_model_optimization as tfmot  #Adding pruning imports\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude   #Adding pruning imports\n",
    "    \n",
    "\n",
    "\n",
    "    epochs = 2\n",
    "    num_images = 18000\n",
    "    end_step = np.ceil(num_images / 8).astype(np.int32) * epochs\n",
    "    print(\"End_step -> \",end_step)\n",
    "\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "    }\n",
    "\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(64, kernel_size=3, activation='relu'), **pruning_params)\n",
    "\n",
    "    \n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), **pruning_params))\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.MaxPooling2D(pool_size=(2, 2)), **pruning_params)\n",
    "\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params)])\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(conv1, **pruning_params)])\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mohan/mlp/git/mltf114_pip2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohan/mlp/git/mltf114_pip2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mohan/mlp/git/mltf114_pip2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 480, 3)]     0         \n",
      "_________________________________________________________________\n",
      "identity_layer (Lambda)      (None, 300, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 300, 480, 32)      2432      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 300, 480, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu1 (ELU)                   (None, 300, 480, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 150, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 150, 240, 48)      13872     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 150, 240, 48)      192       \n",
      "_________________________________________________________________\n",
      "elu2 (ELU)                   (None, 150, 240, 48)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 75, 120, 48)       0         \n",
      "=================================================================\n",
      "Total params: 16,624\n",
      "Trainable params: 16,464\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "conv1\n"
     ]
    }
   ],
   "source": [
    "    from __future__ import division\n",
    "    import numpy as np\n",
    "    #from keras.models import Model\n",
    "    #from keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, ELU, Reshape, Concatenate, Activation\n",
    "    from keras.regularizers import l2\n",
    "    import keras.backend as K\n",
    "\n",
    "    from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "    from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "    from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    img_height = 300 # Height of the input images\n",
    "    img_width = 480 # Width of the input images\n",
    "    img_channels = 3 # Number of color channels of the input images\n",
    "    intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "    intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "    n_classes = 5 # Number of positive classes\n",
    "    scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "    aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "    two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "    steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "    offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
    "    clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "    variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
    "    normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size\n",
    "\n",
    "\n",
    "    l2_regularization=0.0\n",
    "    image_size=(img_height, img_width, img_channels)\n",
    "    aspect_ratios_global=[0.5, 1.0, 2.0]\n",
    "    aspect_ratios_per_layer=None\n",
    "    min_scale=0.1\n",
    "    max_scale=0.9\n",
    "    subtract_mean=None\n",
    "    divide_by_stddev=None\n",
    "    swap_channels=False\n",
    "    confidence_thresh=0.01\n",
    "    iou_threshold=0.45\n",
    "    top_k=200\n",
    "    nms_max_output_size=400\n",
    "    return_predictor_sizes=False\n",
    "    coords='centroids'\n",
    "    mode='training'\n",
    "\n",
    "\n",
    "    n_predictor_layers = 4 # The number of predictor conv layers in the network\n",
    "    n_classes += 1 # Account for the background class.\n",
    "    l2_reg = l2_regularization # Make the internal name shorter.\n",
    "    img_height, img_width, img_channels = image_size[0], image_size[1], image_size[2]\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    # Get a few exceptions out of the way.\n",
    "    ############################################################################\n",
    "\n",
    "    if aspect_ratios_global is None and aspect_ratios_per_layer is None:\n",
    "        raise ValueError(\"`aspect_ratios_global` and `aspect_ratios_per_layer` cannot both be None. At least one needs to be specified.\")\n",
    "    if aspect_ratios_per_layer:\n",
    "        if len(aspect_ratios_per_layer) != n_predictor_layers:\n",
    "            raise ValueError(\"It must be either aspect_ratios_per_layer is None or len(aspect_ratios_per_layer) == {}, but len(aspect_ratios_per_layer) == {}.\".format(n_predictor_layers, len(aspect_ratios_per_layer)))\n",
    "\n",
    "    if (min_scale is None or max_scale is None) and scales is None:\n",
    "        raise ValueError(\"Either `min_scale` and `max_scale` or `scales` need to be specified.\")\n",
    "    if scales:\n",
    "        if len(scales) != n_predictor_layers+1:\n",
    "            raise ValueError(\"It must be either scales is None or len(scales) == {}, but len(scales) == {}.\".format(n_predictor_layers+1, len(scales)))\n",
    "    else: # If no explicit list of scaling factors was passed, compute the list of scaling factors from `min_scale` and `max_scale`\n",
    "        scales = np.linspace(min_scale, max_scale, n_predictor_layers+1)\n",
    "\n",
    "    if len(variances) != 4: # We need one variance value for each of the four box coordinates\n",
    "        raise ValueError(\"4 variance values must be pased, but {} values were received.\".format(len(variances)))\n",
    "    variances = np.array(variances)\n",
    "    if np.any(variances <= 0):\n",
    "        raise ValueError(\"All variances must be >0, but the variances given are {}\".format(variances))\n",
    "\n",
    "    if (not (steps is None)) and (len(steps) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one step value per predictor layer.\")\n",
    "\n",
    "    if (not (offsets is None)) and (len(offsets) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one offset value per predictor layer.\")\n",
    "\n",
    "    ############################################################################\n",
    "    # Compute the anchor box parameters.\n",
    "    ############################################################################\n",
    "\n",
    "    # Set the aspect ratios for each predictor layer. These are only needed for the anchor box layers.\n",
    "    if aspect_ratios_per_layer:\n",
    "        aspect_ratios = aspect_ratios_per_layer\n",
    "    else:\n",
    "        aspect_ratios = [aspect_ratios_global] * n_predictor_layers\n",
    "\n",
    "    # Compute the number of boxes to be predicted per cell for each predictor layer.\n",
    "    # We need this so that we know how many channels the predictor layers need to have.\n",
    "    if aspect_ratios_per_layer:\n",
    "        n_boxes = []\n",
    "        for ar in aspect_ratios_per_layer:\n",
    "            if (1 in ar) & two_boxes_for_ar1:\n",
    "                n_boxes.append(len(ar) + 1) # +1 for the second box for aspect ratio 1\n",
    "            else:\n",
    "                n_boxes.append(len(ar))\n",
    "    else: # If only a global aspect ratio list was passed, then the number of boxes is the same for each predictor layer\n",
    "        if (1 in aspect_ratios_global) & two_boxes_for_ar1:\n",
    "            n_boxes = len(aspect_ratios_global) + 1\n",
    "        else:\n",
    "            n_boxes = len(aspect_ratios_global)\n",
    "        n_boxes = [n_boxes] * n_predictor_layers\n",
    "\n",
    "    if steps is None:\n",
    "        steps = [None] * n_predictor_layers\n",
    "    if offsets is None:\n",
    "        offsets = [None] * n_predictor_layers\n",
    "\n",
    "    ############################################################################\n",
    "    # Define functions for the Lambda layers below.\n",
    "    ############################################################################\n",
    "\n",
    "    def identity_layer(tensor):\n",
    "        return tensor\n",
    "\n",
    "    def input_mean_normalization(tensor):\n",
    "        return tensor - np.array(subtract_mean)\n",
    "\n",
    "    def input_stddev_normalization(tensor):\n",
    "        return tensor / np.array(divide_by_stddev)\n",
    "\n",
    "    def input_channel_swap(tensor):\n",
    "        if len(swap_channels) == 3:\n",
    "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]]], axis=-1)\n",
    "        elif len(swap_channels) == 4:\n",
    "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]], tensor[...,swap_channels[3]]], axis=-1)\n",
    "\n",
    "    ############################################################################\n",
    "    # Build the network.\n",
    "    ############################################################################\n",
    "\n",
    "    x = keras.layers.Input(shape=(img_height, img_width, img_channels))\n",
    "\n",
    "    # The following identity layer is only needed so that the subsequent lambda layers can be optional.\n",
    "    x1 = keras.layers.Lambda(identity_layer, output_shape=(img_height, img_width, img_channels), name='identity_layer')(x)\n",
    "    if not (subtract_mean is None):\n",
    "        x1 = keras.layers.Lambda(input_mean_normalization, output_shape=(img_height, img_width, img_channels), name='input_mean_normalization')(x1)\n",
    "    if not (divide_by_stddev is None):\n",
    "        x1 = keras.layers.Lambda(input_stddev_normalization, output_shape=(img_height, img_width, img_channels), name='input_stddev_normalization')(x1)\n",
    "    if swap_channels:\n",
    "        x1 = keras.layers.Lambda(input_channel_swap, output_shape=(img_height, img_width, img_channels), name='input_channel_swap')(x1)\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x1)\n",
    "    conv1 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1) # Tensorflow uses filter format [filter_height, filter_width, in_channels, out_channels], hence axis = 3\n",
    "    conv1 = keras.layers.ELU(name='elu1')(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "    \n",
    "    conv2 = keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "    conv2 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "    conv2 = keras.layers.ELU(name='elu2')(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "    ############################################################################\n",
    "    # Pruning begin\n",
    "    ############################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "    \n",
    "    #model_for_pruning = tf.keras.Sequential([\n",
    "  #tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params),\n",
    "  \n",
    "#])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), **pruning_params))\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.MaxPooling2D(pool_size=(2, 2)), **pruning_params)\n",
    "\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params)])\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(conv1, **pruning_params)])\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Pruning end\n",
    "    ############################################################################\n",
    "\n",
    "\n",
    "    if mode == 'training':\n",
    "        model = keras.models.Model(inputs=x, outputs=pool2)\n",
    "        model.summary()\n",
    "        print(model.layers[2].name)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model_for_pruning = tf.keras.models.Model([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params),\n",
    "  \n",
    "])\n",
    "    \n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    #model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 480, 3)]     0         \n",
      "_________________________________________________________________\n",
      "identity_layer (Lambda)      (None, 300, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 300, 480, 32)      2432      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 300, 480, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu1 (ELU)                   (None, 300, 480, 32)      0         \n",
      "=================================================================\n",
      "Total params: 2,560\n",
      "Trainable params: 2,496\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-08315482b8ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m   tfmot.sparsity.keras.prune_low_magnitude(keras.layers.Conv2D(32, (5, 5)))])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_for_pruning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp/git/mltf114_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \"\"\"\n\u001b[1;32m   1503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1505\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Use `prune_low_magnitude` to make the `MyDenseLayer` layer train with pruning.\n",
    "\n",
    "model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(keras.layers.Conv2D(32, (5, 5)))])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mohan/mlp/git/mltf114_pip2/lib/python3.6/site-packages/tensorflow/python/autograph/converters/directives.py:117: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03baeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03baeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03baeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03baeb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mohan/mlp/git/mltf114_pip2/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/keras/compat.py:25: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03d6198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03d6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03d6198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x7fcce03d6198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 300, 480, 3)]     0         \n",
      "_________________________________________________________________\n",
      "identity_layer (Lambda)      (None, 300, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv1 (P (None, 300, 480, 32)      4834      \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 300, 480, 32)      128       \n",
      "_________________________________________________________________\n",
      "elu1 (ELU)                   (None, 300, 480, 32)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 150, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2 (P (None, 150, 240, 48)      27698     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 150, 240, 48)      192       \n",
      "_________________________________________________________________\n",
      "elu2 (ELU)                   (None, 150, 240, 48)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 75, 120, 48)       0         \n",
      "=================================================================\n",
      "Total params: 32,852\n",
      "Trainable params: 16,464\n",
      "Non-trainable params: 16,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Helper function uses `prune_low_magnitude` to make only the \n",
    "# Dense layers train with pruning.\n",
    "def apply_pruning_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End_step ->  4500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4660a765a7f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m           metrics=['accuracy'])\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel_for_pruning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp/git/mltf114_pip2/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \"\"\"\n\u001b[1;32m   1503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1504\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1505\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "    import tensorflow_model_optimization as tfmot  #Adding pruning imports\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude   #Adding pruning imports\n",
    "    \n",
    "    from tensorflow import keras\n",
    "\n",
    "    epochs = 2\n",
    "    num_images = 18000\n",
    "    end_step = np.ceil(num_images / 8).astype(np.int32) * epochs\n",
    "    print(\"End_step -> \",end_step)\n",
    "\n",
    "    # Define model for pruning.\n",
    "    pruning_params = {\n",
    "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "    }\n",
    "\n",
    "    #model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "    \n",
    "    model_for_pruning = tf.keras.Sequential([\n",
    "  tfmot.sparsity.keras.prune_low_magnitude(tf.keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params),\n",
    "  \n",
    "])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), **pruning_params))\n",
    "    #model_for_pruning = prune_low_magnitude(keras.layers.MaxPooling2D(pool_size=(2, 2)), **pruning_params)\n",
    "\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg)), **pruning_params)])\n",
    "    #model_for_pruning = keras.Sequential([prune_low_magnitude(conv1, **pruning_params)])\n",
    "\n",
    "    # `prune_low_magnitude` requires a recompile.\n",
    "    model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'output_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-90e21b8055a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    220\u001b[0m anchors4 = AnchorBoxes(img_height, img_width, this_scale=scales[0], next_scale=scales[1], aspect_ratios=aspect_ratios[0],\n\u001b[1;32m    221\u001b[0m                        \u001b[0mtwo_boxes_for_ar1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwo_boxes_for_ar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_offsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                        clip_boxes=clip_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors4')(boxes4)\n\u001b[0m\u001b[1;32m    223\u001b[0m anchors5 = AnchorBoxes(img_height, img_width, this_scale=scales[1], next_scale=scales[2], aspect_ratios=aspect_ratios[1],\n\u001b[1;32m    224\u001b[0m                        \u001b[0mtwo_boxes_for_ar1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwo_boxes_for_ar1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_offsets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp/git/mltf114_pip2/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mprevious_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_all_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp/git/mltf114_pip2/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[0;34m(input_tensors)\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"
     ]
    }
   ],
   "source": [
    "    from __future__ import division\n",
    "    import numpy as np\n",
    "    #from keras.models import Model\n",
    "    #from keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, ELU, Reshape, Concatenate, Activation\n",
    "    from keras.regularizers import l2\n",
    "    import keras.backend as K\n",
    "    \n",
    "    from tensorflow import keras\n",
    "\n",
    "    from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "    from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "    from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "    K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "    img_height = 300 # Height of the input images\n",
    "    img_width = 480 # Width of the input images\n",
    "    img_channels = 3 # Number of color channels of the input images\n",
    "    intensity_mean = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "    intensity_range = 127.5 # Set this to your preference (maybe `None`). The current settings transform the input pixel values to the interval `[-1,1]`.\n",
    "    n_classes = 5 # Number of positive classes\n",
    "    scales = [0.08, 0.16, 0.32, 0.64, 0.96] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "    aspect_ratios = [0.5, 1.0, 2.0] # The list of aspect ratios for the anchor boxes\n",
    "    two_boxes_for_ar1 = True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "    steps = None # In case you'd like to set the step sizes for the anchor box grids manually; not recommended\n",
    "    offsets = None # In case you'd like to set the offsets for the anchor box grids manually; not recommended\n",
    "    clip_boxes = False # Whether or not to clip the anchor boxes to lie entirely within the image boundaries\n",
    "    variances = [1.0, 1.0, 1.0, 1.0] # The list of variances by which the encoded target coordinates are scaled\n",
    "    normalize_coords = True # Whether or not the model is supposed to use coordinates relative to the image size\n",
    "\n",
    "\n",
    "    l2_regularization=0.0\n",
    "    image_size=(img_height, img_width, img_channels)\n",
    "    aspect_ratios_global=[0.5, 1.0, 2.0]\n",
    "    aspect_ratios_per_layer=None\n",
    "    min_scale=0.1\n",
    "    max_scale=0.9\n",
    "    subtract_mean=None\n",
    "    divide_by_stddev=None\n",
    "    swap_channels=False\n",
    "    confidence_thresh=0.01\n",
    "    iou_threshold=0.45\n",
    "    top_k=200\n",
    "    nms_max_output_size=400\n",
    "    return_predictor_sizes=False\n",
    "    coords='centroids'\n",
    "    mode='training'\n",
    "\n",
    "\n",
    "    n_predictor_layers = 4 # The number of predictor conv layers in the network\n",
    "    n_classes += 1 # Account for the background class.\n",
    "    l2_reg = l2_regularization # Make the internal name shorter.\n",
    "    img_height, img_width, img_channels = image_size[0], image_size[1], image_size[2]\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    # Get a few exceptions out of the way.\n",
    "    ############################################################################\n",
    "\n",
    "    if aspect_ratios_global is None and aspect_ratios_per_layer is None:\n",
    "        raise ValueError(\"`aspect_ratios_global` and `aspect_ratios_per_layer` cannot both be None. At least one needs to be specified.\")\n",
    "    if aspect_ratios_per_layer:\n",
    "        if len(aspect_ratios_per_layer) != n_predictor_layers:\n",
    "            raise ValueError(\"It must be either aspect_ratios_per_layer is None or len(aspect_ratios_per_layer) == {}, but len(aspect_ratios_per_layer) == {}.\".format(n_predictor_layers, len(aspect_ratios_per_layer)))\n",
    "\n",
    "    if (min_scale is None or max_scale is None) and scales is None:\n",
    "        raise ValueError(\"Either `min_scale` and `max_scale` or `scales` need to be specified.\")\n",
    "    if scales:\n",
    "        if len(scales) != n_predictor_layers+1:\n",
    "            raise ValueError(\"It must be either scales is None or len(scales) == {}, but len(scales) == {}.\".format(n_predictor_layers+1, len(scales)))\n",
    "    else: # If no explicit list of scaling factors was passed, compute the list of scaling factors from `min_scale` and `max_scale`\n",
    "        scales = np.linspace(min_scale, max_scale, n_predictor_layers+1)\n",
    "\n",
    "    if len(variances) != 4: # We need one variance value for each of the four box coordinates\n",
    "        raise ValueError(\"4 variance values must be pased, but {} values were received.\".format(len(variances)))\n",
    "    variances = np.array(variances)\n",
    "    if np.any(variances <= 0):\n",
    "        raise ValueError(\"All variances must be >0, but the variances given are {}\".format(variances))\n",
    "\n",
    "    if (not (steps is None)) and (len(steps) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one step value per predictor layer.\")\n",
    "\n",
    "    if (not (offsets is None)) and (len(offsets) != n_predictor_layers):\n",
    "        raise ValueError(\"You must provide at least one offset value per predictor layer.\")\n",
    "\n",
    "    ############################################################################\n",
    "    # Compute the anchor box parameters.\n",
    "    ############################################################################\n",
    "\n",
    "    # Set the aspect ratios for each predictor layer. These are only needed for the anchor box layers.\n",
    "    if aspect_ratios_per_layer:\n",
    "        aspect_ratios = aspect_ratios_per_layer\n",
    "    else:\n",
    "        aspect_ratios = [aspect_ratios_global] * n_predictor_layers\n",
    "\n",
    "    # Compute the number of boxes to be predicted per cell for each predictor layer.\n",
    "    # We need this so that we know how many channels the predictor layers need to have.\n",
    "    if aspect_ratios_per_layer:\n",
    "        n_boxes = []\n",
    "        for ar in aspect_ratios_per_layer:\n",
    "            if (1 in ar) & two_boxes_for_ar1:\n",
    "                n_boxes.append(len(ar) + 1) # +1 for the second box for aspect ratio 1\n",
    "            else:\n",
    "                n_boxes.append(len(ar))\n",
    "    else: # If only a global aspect ratio list was passed, then the number of boxes is the same for each predictor layer\n",
    "        if (1 in aspect_ratios_global) & two_boxes_for_ar1:\n",
    "            n_boxes = len(aspect_ratios_global) + 1\n",
    "        else:\n",
    "            n_boxes = len(aspect_ratios_global)\n",
    "        n_boxes = [n_boxes] * n_predictor_layers\n",
    "\n",
    "    if steps is None:\n",
    "        steps = [None] * n_predictor_layers\n",
    "    if offsets is None:\n",
    "        offsets = [None] * n_predictor_layers\n",
    "\n",
    "    ############################################################################\n",
    "    # Define functions for the Lambda layers below.\n",
    "    ############################################################################\n",
    "\n",
    "    def identity_layer(tensor):\n",
    "        return tensor\n",
    "\n",
    "    def input_mean_normalization(tensor):\n",
    "        return tensor - np.array(subtract_mean)\n",
    "\n",
    "    def input_stddev_normalization(tensor):\n",
    "        return tensor / np.array(divide_by_stddev)\n",
    "\n",
    "    def input_channel_swap(tensor):\n",
    "        if len(swap_channels) == 3:\n",
    "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]]], axis=-1)\n",
    "        elif len(swap_channels) == 4:\n",
    "            return K.stack([tensor[...,swap_channels[0]], tensor[...,swap_channels[1]], tensor[...,swap_channels[2]], tensor[...,swap_channels[3]]], axis=-1)\n",
    "\n",
    "    ############################################################################\n",
    "    # Build the network.\n",
    "    ############################################################################\n",
    "\n",
    "    x = keras.layers.Input(shape=(img_height, img_width, img_channels))\n",
    "\n",
    "    # The following identity layer is only needed so that the subsequent lambda layers can be optional.\n",
    "    x1 = keras.layers.Lambda(identity_layer, output_shape=(img_height, img_width, img_channels), name='identity_layer')(x)\n",
    "    if not (subtract_mean is None):\n",
    "        x1 = keras.layers.Lambda(input_mean_normalization, output_shape=(img_height, img_width, img_channels), name='input_mean_normalization')(x1)\n",
    "    if not (divide_by_stddev is None):\n",
    "        x1 = keras.layers.Lambda(input_stddev_normalization, output_shape=(img_height, img_width, img_channels), name='input_stddev_normalization')(x1)\n",
    "    if swap_channels:\n",
    "        x1 = keras.layers.Lambda(input_channel_swap, output_shape=(img_height, img_width, img_channels), name='input_channel_swap')(x1)\n",
    "\n",
    "    conv1 = keras.layers.Conv2D(32, (5, 5), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv1')(x1)\n",
    "    conv1 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn1')(conv1) # Tensorflow uses filter format [filter_height, filter_width, in_channels, out_channels], hence axis = 3\n",
    "    conv1 = keras.layers.ELU(name='elu1')(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "    \n",
    "    ############################################################################\n",
    "    # Pruning begin\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # Pruning end\n",
    "    ############################################################################\n",
    "\n",
    "    conv2 = keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv2')(pool1)\n",
    "    conv2 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn2')(conv2)\n",
    "    conv2 = keras.layers.ELU(name='elu2')(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv3')(pool2)\n",
    "    conv3 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn3')(conv3)\n",
    "    conv3 = keras.layers.ELU(name='elu3')(conv3)\n",
    "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "    conv4 = keras.layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv4')(pool3)\n",
    "    conv4 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn4')(conv4)\n",
    "    conv4 = keras.layers.ELU(name='elu4')(conv4)\n",
    "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "    conv5 = keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv5')(pool4)\n",
    "    conv5 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn5')(conv5)\n",
    "    conv5 = keras.layers.ELU(name='elu5')(conv5)\n",
    "    pool5 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool5')(conv5)\n",
    "\n",
    "    conv6 = keras.layers.Conv2D(48, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv6')(pool5)\n",
    "    conv6 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn6')(conv6)\n",
    "    conv6 = keras.layers.ELU(name='elu6')(conv6)\n",
    "    pool6 = keras.layers.MaxPooling2D(pool_size=(2, 2), name='pool6')(conv6)\n",
    "\n",
    "    conv7 = keras.layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='conv7')(pool6)\n",
    "    conv7 = keras.layers.BatchNormalization(axis=3, momentum=0.99, name='bn7')(conv7)\n",
    "    conv7 = keras.layers.ELU(name='elu7')(conv7)\n",
    "\n",
    "    # The next part is to add the convolutional predictor layers on top of the base network\n",
    "    # that we defined above. Note that I use the term \"base network\" differently than the paper does.\n",
    "    # To me, the base network is everything that is not convolutional predictor layers or anchor\n",
    "    # box layers. In this case we'll have four predictor layers, but of course you could\n",
    "    # easily rewrite this into an arbitrarily deep base network and add an arbitrary number of\n",
    "    # predictor layers on top of the base network by simply following the pattern shown here.\n",
    "\n",
    "    # Build the convolutional predictor layers on top of conv layers 4, 5, 6, and 7.\n",
    "    # We build two predictor layers on top of each of these layers: One for class prediction (classification), one for box coordinate prediction (localization)\n",
    "    # We precidt `n_classes` confidence values for each box, hence the `classes` predictors have depth `n_boxes * n_classes`\n",
    "    # We predict 4 box coordinates for each box, hence the `boxes` predictors have depth `n_boxes * 4`\n",
    "    # Output shape of `classes`: `(batch, height, width, n_boxes * n_classes)`\n",
    "    classes4 = keras.layers.Conv2D(n_boxes[0] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes4')(conv4)\n",
    "    classes5 = keras.layers.Conv2D(n_boxes[1] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes5')(conv5)\n",
    "    classes6 = keras.layers.Conv2D(n_boxes[2] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes6')(conv6)\n",
    "    classes7 = keras.layers.Conv2D(n_boxes[3] * n_classes, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='classes7')(conv7)\n",
    "    # Output shape of `boxes`: `(batch, height, width, n_boxes * 4)`\n",
    "    boxes4 = keras.layers.Conv2D(n_boxes[0] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes4')(conv4)\n",
    "    boxes5 = keras.layers.Conv2D(n_boxes[1] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes5')(conv5)\n",
    "    boxes6 = keras.layers.Conv2D(n_boxes[2] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes6')(conv6)\n",
    "    boxes7 = keras.layers.Conv2D(n_boxes[3] * 4, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal', kernel_regularizer=l2(l2_reg), name='boxes7')(conv7)\n",
    "\n",
    "    # Generate the anchor boxes\n",
    "    # Output shape of `anchors`: `(batch, height, width, n_boxes, 8)`\n",
    "    anchors4 = AnchorBoxes(img_height, img_width, this_scale=scales[0], next_scale=scales[1], aspect_ratios=aspect_ratios[0],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[0], this_offsets=offsets[0],\n",
    "                           clip_boxes=clip_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors4')(boxes4)\n",
    "    anchors5 = AnchorBoxes(img_height, img_width, this_scale=scales[1], next_scale=scales[2], aspect_ratios=aspect_ratios[1],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[1], this_offsets=offsets[1],\n",
    "                           clip_boxes=clip_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors5')(boxes5)\n",
    "    anchors6 = AnchorBoxes(img_height, img_width, this_scale=scales[2], next_scale=scales[3], aspect_ratios=aspect_ratios[2],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[2], this_offsets=offsets[2],\n",
    "                           clip_boxes=clip_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors6')(boxes6)\n",
    "    anchors7 = AnchorBoxes(img_height, img_width, this_scale=scales[3], next_scale=scales[4], aspect_ratios=aspect_ratios[3],\n",
    "                           two_boxes_for_ar1=two_boxes_for_ar1, this_steps=steps[3], this_offsets=offsets[3],\n",
    "                           clip_boxes=clip_boxes, variances=variances, coords=coords, normalize_coords=normalize_coords, name='anchors7')(boxes7)\n",
    "\n",
    "    # Reshape the class predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, n_classes)`\n",
    "    # We want the classes isolated in the last axis to perform softmax on them\n",
    "    classes4_reshaped = keras.layers.Reshape((-1, n_classes), name='classes4_reshape')(classes4)\n",
    "    classes5_reshaped = keras.layers.Reshape((-1, n_classes), name='classes5_reshape')(classes5)\n",
    "    classes6_reshaped = keras.layers.Reshape((-1, n_classes), name='classes6_reshape')(classes6)\n",
    "    classes7_reshaped = keras.layers.Reshape((-1, n_classes), name='classes7_reshape')(classes7)\n",
    "    # Reshape the box coordinate predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, 4)`\n",
    "    # We want the four box coordinates isolated in the last axis to compute the smooth L1 loss\n",
    "    boxes4_reshaped = keras.layers.Reshape((-1, 4), name='boxes4_reshape')(boxes4)\n",
    "    boxes5_reshaped = keras.layers.Reshape((-1, 4), name='boxes5_reshape')(boxes5)\n",
    "    boxes6_reshaped = keras.layers.Reshape((-1, 4), name='boxes6_reshape')(boxes6)\n",
    "    boxes7_reshaped = keras.layers.Reshape((-1, 4), name='boxes7_reshape')(boxes7)\n",
    "    # Reshape the anchor box tensors, yielding 3D tensors of shape `(batch, height * width * n_boxes, 8)`\n",
    "    anchors4_reshaped = keras.layers.Reshape((-1, 8), name='anchors4_reshape')(anchors4)\n",
    "    anchors5_reshaped = keras.layers.Reshape((-1, 8), name='anchors5_reshape')(anchors5)\n",
    "    anchors6_reshaped = keras.layers.Reshape((-1, 8), name='anchors6_reshape')(anchors6)\n",
    "    anchors7_reshaped = keras.layers.Reshape((-1, 8), name='anchors7_reshape')(anchors7)\n",
    "\n",
    "    # Concatenate the predictions from the different layers and the assosciated anchor box tensors\n",
    "    # Axis 0 (batch) and axis 2 (n_classes or 4, respectively) are identical for all layer predictions,\n",
    "    # so we want to concatenate along axis 1\n",
    "    # Output shape of `classes_concat`: (batch, n_boxes_total, n_classes)\n",
    "    classes_concat = keras.layers.Concatenate(axis=1, name='classes_concat')([classes4_reshaped,\n",
    "                                                                 classes5_reshaped,\n",
    "                                                                 classes6_reshaped,\n",
    "                                                                 classes7_reshaped])\n",
    "\n",
    "    # Output shape of `boxes_concat`: (batch, n_boxes_total, 4)\n",
    "    boxes_concat = keras.layers.Concatenate(axis=1, name='boxes_concat')([boxes4_reshaped,\n",
    "                                                             boxes5_reshaped,\n",
    "                                                             boxes6_reshaped,\n",
    "                                                             boxes7_reshaped])\n",
    "\n",
    "    # Output shape of `anchors_concat`: (batch, n_boxes_total, 8)\n",
    "    anchors_concat = keras.layers.Concatenate(axis=1, name='anchors_concat')([anchors4_reshaped,\n",
    "                                                                 anchors5_reshaped,\n",
    "                                                                 anchors6_reshaped,\n",
    "                                                                 anchors7_reshaped])\n",
    "\n",
    "    # The box coordinate predictions will go into the loss function just the way they are,\n",
    "    # but for the class predictions, we'll apply a softmax activation layer first\n",
    "    classes_softmax = keras.layers.Activation('softmax', name='classes_softmax')(classes_concat)\n",
    "\n",
    "    # Concatenate the class and box coordinate predictions and the anchors to one large predictions tensor\n",
    "    # Output shape of `predictions`: (batch, n_boxes_total, n_classes + 4 + 8)\n",
    "    predictions = keras.layers.Concatenate(axis=2, name='predictions')([classes_softmax, boxes_concat, anchors_concat])\n",
    "    \n",
    "    #print(\"Value of x ->\", x)\n",
    "    #print(\"Output  ->\", predictions)\n",
    "\n",
    "    if mode == 'training':\n",
    "        model = keras.models.Model(inputs=x, outputs=predictions)\n",
    "        model.summary()\n",
    "    elif mode == 'inference':\n",
    "        decoded_predictions = DecodeDetections(confidence_thresh=confidence_thresh,\n",
    "                                               iou_threshold=iou_threshold,\n",
    "                                               top_k=top_k,\n",
    "                                               nms_max_output_size=nms_max_output_size,\n",
    "                                               coords=coords,\n",
    "                                               normalize_coords=normalize_coords,\n",
    "                                               img_height=img_height,\n",
    "                                               img_width=img_width,\n",
    "                                               name='decoded_predictions')(predictions)\n",
    "        model = keras.models.Model(inputs=x, outputs=decoded_predictions)\n",
    "    elif mode == 'inference_fast':\n",
    "        decoded_predictions = DecodeDetectionsFast(confidence_thresh=confidence_thresh,\n",
    "                                                   iou_threshold=iou_threshold,\n",
    "                                                   top_k=top_k,\n",
    "                                                   nms_max_output_size=nms_max_output_size,\n",
    "                                                   coords=coords,\n",
    "                                                   normalize_coords=normalize_coords,\n",
    "                                                   img_height=img_height,\n",
    "                                                   img_width=img_width,\n",
    "                                                   name='decoded_predictions')(predictions)\n",
    "        model = keras.models.Model(inputs=x, outputs=decoded_predictions)\n",
    "        model.summary()\n",
    "    else:\n",
    "        raise ValueError(\"`mode` must be one of 'training', 'inference' or 'inference_fast', but received '{}'.\".format(mode))\n",
    "\n",
    "    if return_predictor_sizes:\n",
    "        # The spatial dimensions are the same for the `classes` and `boxes` predictor layers.\n",
    "        predictor_sizes = np.array([classes4._keras_shape[1:3],\n",
    "                                    classes5._keras_shape[1:3],\n",
    "                                    classes6._keras_shape[1:3],\n",
    "                                    classes7._keras_shape[1:3]])\n",
    "        model, predictor_sizes\n",
    "    else:\n",
    "        model\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
